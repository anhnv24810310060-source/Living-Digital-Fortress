---
# Prometheus ServiceMonitor for Credits Service
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: credits-service-monitor
  namespace: shieldx-prod
  labels:
    app: credits-service
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: credits-service
  endpoints:
    - port: http
      path: /metrics
      interval: 15s
      scrapeTimeout: 10s

---
# Prometheus ServiceMonitor for Shadow Service
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: shadow-service-monitor
  namespace: shieldx-prod
  labels:
    app: shadow-service
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: shadow-service
  endpoints:
    - port: http
      path: /metrics
      interval: 15s
      scrapeTimeout: 10s

---
# PrometheusRule - Credits Service Alerts
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: credits-service-alerts
  namespace: shieldx-prod
  labels:
    app: credits-service
    prometheus: kube-prometheus
spec:
  groups:
    - name: credits_service
      interval: 30s
      rules:
        # High error rate
        - alert: CreditsHighErrorRate
          expr: |
            (
              rate(credits_operations_total{result="error"}[5m]) 
              / 
              rate(credits_operations_total[5m])
            ) > 0.05
          for: 5m
          labels:
            severity: warning
            service: credits
          annotations:
            summary: "High error rate in Credits service"
            description: "Credits service error rate is {{ $value | humanizePercentage }} (threshold: 5%)"
        
        # Database connection issues
        - alert: CreditsDatabaseConnectionFailure
          expr: |
            rate(credits_operations_total{result="error"}[2m]) > 10
          for: 2m
          labels:
            severity: critical
            service: credits
          annotations:
            summary: "Credits database connection failures"
            description: "Possible database outage affecting Credits service"
        
        # Circuit breaker open
        - alert: CreditsCircuitBreakerOpen
          expr: |
            credits_circuit_breaker_state{state="open"} == 1
          for: 1m
          labels:
            severity: critical
            service: credits
          annotations:
            summary: "Credits circuit breaker is OPEN"
            description: "Credits service circuit breaker has opened due to failures"
        
        # High latency
        - alert: CreditsHighLatency
          expr: |
            histogram_quantile(0.95, 
              rate(http_request_duration_seconds_bucket{service="credits"}[5m])
            ) > 1.0
          for: 5m
          labels:
            severity: warning
            service: credits
          annotations:
            summary: "High latency in Credits service"
            description: "P95 latency is {{ $value }}s (threshold: 1s)"
        
        # Low cache hit rate
        - alert: CreditsLowCacheHitRate
          expr: |
            credits_cache_hit_rate < 0.7
          for: 10m
          labels:
            severity: info
            service: credits
          annotations:
            summary: "Low cache hit rate"
            description: "Credits cache hit rate is {{ $value | humanizePercentage }} (expected >70%)"
        
        # Negative balance attempts
        - alert: CreditsInsufficientFundsSpike
          expr: |
            rate(credits_operations_total{op="consume",result="insufficient"}[5m]) > 50
          for: 5m
          labels:
            severity: warning
            service: credits
          annotations:
            summary: "Spike in insufficient funds errors"
            description: "High rate of insufficient credit attempts: {{ $value }}/s"
        
        # Pod down
        - alert: CreditsPodDown
          expr: |
            kube_deployment_status_replicas_available{deployment="credits-service"} < 2
          for: 2m
          labels:
            severity: critical
            service: credits
          annotations:
            summary: "Credits service has fewer than 2 pods running"
            description: "Only {{ $value }} Credits pods available (minimum: 2)"
        
        # High memory usage
        - alert: CreditsHighMemoryUsage
          expr: |
            (
              container_memory_working_set_bytes{pod=~"credits-service-.*"}
              /
              container_spec_memory_limit_bytes{pod=~"credits-service-.*"}
            ) > 0.85
          for: 10m
          labels:
            severity: warning
            service: credits
          annotations:
            summary: "Credits pod memory usage high"
            description: "Memory usage is {{ $value | humanizePercentage }} of limit"
        
        # CPU throttling
        - alert: CreditsCPUThrottling
          expr: |
            rate(container_cpu_cfs_throttled_seconds_total{pod=~"credits-service-.*"}[5m]) > 0.25
          for: 10m
          labels:
            severity: warning
            service: credits
          annotations:
            summary: "Credits pod is being CPU throttled"
            description: "CPU throttling rate: {{ $value | humanizePercentage }}"

---
# PrometheusRule - Shadow Service Alerts
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: shadow-service-alerts
  namespace: shieldx-prod
  labels:
    app: shadow-service
    prometheus: kube-prometheus
spec:
  groups:
    - name: shadow_service
      interval: 30s
      rules:
        # Evaluation failures
        - alert: ShadowEvaluationFailures
          expr: |
            rate(shadow_evaluation_total{result="error"}[5m]) > 5
          for: 5m
          labels:
            severity: warning
            service: shadow
          annotations:
            summary: "High rate of Shadow evaluation failures"
            description: "Shadow evaluation error rate: {{ $value }}/s"
        
        # Long-running evaluations
        - alert: ShadowLongEvaluations
          expr: |
            histogram_quantile(0.95,
              rate(shadow_evaluation_duration_seconds_bucket[5m])
            ) > 60
          for: 10m
          labels:
            severity: warning
            service: shadow
          annotations:
            summary: "Shadow evaluations taking too long"
            description: "P95 evaluation time: {{ $value }}s (threshold: 60s)"
        
        # Worker pool saturation
        - alert: ShadowWorkerPoolSaturated
          expr: |
            shadow_worker_pool_queue_size > 100
          for: 5m
          labels:
            severity: warning
            service: shadow
          annotations:
            summary: "Shadow worker pool queue is saturated"
            description: "Queue size: {{ $value }} tasks (threshold: 100)"
        
        # Low F1 scores
        - alert: ShadowLowRulePerformance
          expr: |
            shadow_rule_f1_score < 0.7
          for: 30m
          labels:
            severity: info
            service: shadow
          annotations:
            summary: "Shadow rule has low F1 score"
            description: "Rule {{ $labels.rule_id }} F1 score: {{ $value }} (expected >0.7)"
        
        # Pod down
        - alert: ShadowPodDown
          expr: |
            kube_deployment_status_replicas_available{deployment="shadow-service"} < 1
          for: 2m
          labels:
            severity: critical
            service: shadow
          annotations:
            summary: "Shadow service has no pods running"
            description: "All Shadow pods are down!"

---
# Grafana Dashboard ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-person3
  namespace: shieldx-prod
  labels:
    grafana_dashboard: "1"
data:
  person3-services.json: |
    {
      "dashboard": {
        "title": "PERSON 3 Services - Credits & Shadow",
        "uid": "person3-services",
        "timezone": "browser",
        "panels": [
          {
            "id": 1,
            "title": "Credits Operations Rate",
            "targets": [
              {
                "expr": "rate(credits_operations_total[5m])"
              }
            ],
            "type": "graph"
          },
          {
            "id": 2,
            "title": "Credits Error Rate",
            "targets": [
              {
                "expr": "rate(credits_operations_total{result='error'}[5m])"
              }
            ],
            "type": "graph"
          },
          {
            "id": 3,
            "title": "Cache Hit Rate",
            "targets": [
              {
                "expr": "credits_cache_hit_rate"
              }
            ],
            "type": "gauge"
          },
          {
            "id": 4,
            "title": "Shadow Evaluation Duration",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, rate(shadow_evaluation_duration_seconds_bucket[5m]))"
              }
            ],
            "type": "graph"
          },
          {
            "id": 5,
            "title": "Shadow F1 Scores",
            "targets": [
              {
                "expr": "shadow_rule_f1_score"
              }
            ],
            "type": "heatmap"
          },
          {
            "id": 6,
            "title": "Database Connection Pool",
            "targets": [
              {
                "expr": "credits_db_connections_in_use"
              },
              {
                "expr": "credits_db_connections_idle"
              }
            ],
            "type": "graph"
          }
        ]
      }
    }

---
# AlertManager Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config-person3
  namespace: shieldx-prod
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
    
    route:
      receiver: 'person3-team'
      group_by: ['alertname', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      
      routes:
        - match:
            severity: critical
          receiver: 'person3-pager'
          continue: true
        
        - match:
            severity: warning
          receiver: 'person3-slack'
        
        - match:
            severity: info
          receiver: 'person3-email'
    
    receivers:
      - name: 'person3-team'
        webhook_configs:
          - url: 'http://alertmanager-webhook:9093/alerts'
      
      - name: 'person3-pager'
        pagerduty_configs:
          - service_key: '<PAGERDUTY_KEY>'
            description: '{{ .CommonAnnotations.summary }}'
      
      - name: 'person3-slack'
        slack_configs:
          - api_url: '<SLACK_WEBHOOK_URL>'
            channel: '#shieldx-alerts'
            title: '{{ .CommonAnnotations.summary }}'
            text: '{{ .CommonAnnotations.description }}'
      
      - name: 'person3-email'
        email_configs:
          - to: 'person3-team@shieldx.io'
            from: 'alertmanager@shieldx.io'
            smarthost: 'smtp.gmail.com:587'
            auth_username: 'alertmanager@shieldx.io'
            auth_password: '<EMAIL_PASSWORD>'
